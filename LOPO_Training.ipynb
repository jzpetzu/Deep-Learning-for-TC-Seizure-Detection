{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LOPO_Training.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23TOba33L4qf"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1G82GuO-tez"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLTI1HEQ7XnJ"
      },
      "outputs": [],
      "source": [
        "!pip install mne\n",
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3SvD-h7j6QI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler \n",
        "import mne\n",
        "from mne import io\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import CSVLogger\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_addons\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmW9tp_cUV94"
      },
      "outputs": [],
      "source": [
        "# ORIGINAL FILTERING\n",
        "# 10/47 in previous\n",
        "# NEW = 20/47\n",
        "\n",
        "def filter_sequence(sequence, patient_data):\n",
        "  # ISEK recommendations for surface EMG: high pass with 5 Hz cut off, low pass with 500 Hz cutoff.\n",
        "  # https://www1.udel.edu/biology/rosewc/kaap686/notes/EMG%20analysis.pdf\n",
        "  # 30 Hz was optimal high pass cutoff frequency \n",
        "  # High-pass filtering to remove electrocardiographic interference from torso EMG recordings PAPER\n",
        "\n",
        "\n",
        "  lower_sampling = ['train025','train127', 'train163', 'train198', 'train203']\n",
        "\n",
        "  lower_freq = 250\n",
        "\n",
        "  higher_sampling = ['train177', 'train226', 'train178', 'train307', 'train256', 'train275',\n",
        "                      'train291', 'train276', 'train353', 'train349', 'train357']\n",
        "  higher_freq = 256\n",
        "\n",
        "  truncated_name = patient_data[:8]\n",
        "\n",
        "  notch_freqs = np.arange(50, 101, 50)\n",
        "\n",
        "  if truncated_name in lower_sampling:\n",
        "    # filtered_sequence = mne.filter.notch_filter(x = sequence, Fs = lower_freq, freqs = notch_freqs, method = 'iir', iir_params = None, verbose = 0)\n",
        "    filtered_sequence =  mne.filter.filter_data(data = sequence, sfreq = lower_freq, l_freq = 10, h_freq = 47, method='iir', iir_params = None, verbose = 0)\n",
        "    # dict(order=4, ftype='butter', output='sos')\n",
        "    \n",
        "    # print(\"250 Hz sampling rate\")\n",
        "    \n",
        "  \n",
        "  elif truncated_name in higher_sampling:\n",
        "    \n",
        "    #filtered_sequence = mne.filter.notch_filter(x = sequence, Fs = higher_freq, freqs = notch_freqs, method = 'iir', iir_params = None, verbose = 0)\n",
        "    filtered_sequence =  mne.filter.filter_data(data = sequence, sfreq = higher_freq, l_freq = 10, h_freq = 47, method='iir', iir_params = None, verbose = 0)\n",
        "    \n",
        "    # print(\"256 Hz sampling rate\")\n",
        "    \n",
        "  else: \n",
        "    pass\n",
        "\n",
        "  return filtered_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIqSyzJKFuEc"
      },
      "outputs": [],
      "source": [
        "# calculate FAR and specificity - FAR = how many seizures will be decected that arent there in a time series,\n",
        "# Speficiifty - ability to identify all the seizure events\n",
        "\n",
        "def calculate_FAR_Specificity(original_seq, predicted_seq):\n",
        "\n",
        "  # to calculate FAR - get both counts\n",
        "  org_len = len(original_seq) # they are the same but anyway... for clarity\n",
        "  org_count, org_start, org_end = find_seizures(original_seq, org_len)\n",
        "\n",
        "  pred_len = len(predicted_seq) # they are the same but anyway... for clarity\n",
        "  pred_count, pred_start, pred_end = find_seizures(predicted_seq, pred_len)\n",
        "\n",
        "  # seizure counter:\n",
        "  total_seizure_count_predicted = 0\n",
        "  total_seizure_count_real = len(org_count)\n",
        "\n",
        "  # using these counts - need to to first find if seizures in org are in predicted at least partially\n",
        "  for i in range(0, len(org_count)): # iterate through all seizures found in original\n",
        "\n",
        "    for j in range(0, len(pred_count)): # iterate through predicted seizure log\n",
        "      # 4 cases - either wholly inside the actual seizure, encompass all the seizure and beyond, partially find on one side, partially on the other\n",
        "      if (pred_start[j] <= org_start[i] and pred_end[j] >= org_end[i]) or (pred_start[j] <= org_start[i] and (org_start[i] <= pred_end[j] <= org_end[i])) or ((org_start[i] <= pred_start[j] <= org_end[i]) and pred_end[j] >= org_end[i]) or (org_start[i] <= pred_start[j] and pred_end[j] <= org_end[i]):\n",
        "        total_seizure_count_predicted += 1\n",
        "      \n",
        "      else:\n",
        "        continue \n",
        "\n",
        "  \n",
        "  # print(\"predicted:\", total_seizure_count_predicted)\n",
        "  # print(\"real:\", total_seizure_count_real)\n",
        "  print(\"Total seizures predicted:\", total_seizure_count_predicted)\n",
        "  print(\"Total seizures real:\", total_seizure_count_real)\n",
        "\n",
        "  if total_seizure_count_real == 0:\n",
        "    sensitivity = 1\n",
        "  \n",
        "  else:\n",
        "    sensitivity = total_seizure_count_predicted/total_seizure_count_real\n",
        "  \n",
        "  # just extract number of false alarams\n",
        "  pred_count_number = len(pred_count)\n",
        "\n",
        "  far_count = pred_count_number - total_seizure_count_predicted\n",
        "\n",
        "  # To calculate FAR - take the length of the recording in hours and calculate amount of false seizures/hour\n",
        "  length_segments = len(original_seq)\n",
        "  # each segment = 2 seconds, non overlapping! \n",
        "  # 1 hour = 60 mins = 3600 seconds\n",
        "  seconds = length_segments * 8 # --> = 8 for 2000 length segments\n",
        "  # seconds = length_segments*4 # --> = 4 for 1000 length segments\n",
        "  # seconds = length_segments*2 # --> = 2 for 500 length segments\n",
        "  minutes = seconds/60\n",
        "  hours = minutes/60\n",
        "  print(\"Recording length: {} hours\".format(hours))\n",
        "\n",
        "  far = far_count/hours\n",
        "  \n",
        "  print(\"The prediction sensitivity: \", sensitivity)\n",
        "  print(\"The prediction False Alarm Rate FA/h: \", far )\n",
        "\n",
        "  return far, sensitivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmJkTET_3xOT"
      },
      "outputs": [],
      "source": [
        "def eliminate_isolates(sequence, threshold):\n",
        "  # threshold sets the prediction cutoff - how many consequite seizures are required to escape elimination (seizures usually typical length etc.)\n",
        "  seq_length = len(sequence)\n",
        "  seq_count, seq_start, seq_end = find_seizures(sequence, seq_length)\n",
        "  final_seq = sequence\n",
        "\n",
        "  for k in range(0, len(seq_count)):\n",
        "    if seq_count[k] < threshold:\n",
        "  # alter the sequence inside the below threshold segment\n",
        "      for l in range(seq_start[k], seq_end[k]+1):\n",
        "        final_seq[l] = 0  \n",
        "        \n",
        "  return final_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DAmImJr3xOT"
      },
      "outputs": [],
      "source": [
        "def predictions_post_processing(real, predictions, seizure_count, start_seizure, stop_seizure, max_distance_filter, threshold):\n",
        "  # max distance filter allows for tuning of the concatenation scope\n",
        "  # function concatenates closeby seizure events, and discards isolated positive predictions as false\n",
        "  # 10 distance scope = approx 20 seconds\n",
        "  \n",
        "  processed_predictions = predictions\n",
        "  \n",
        "\n",
        "  # concatenation portion of the function\n",
        "  for i in range(0, len(seizure_count)-1):\n",
        "    distance_to_next_seizure = start_seizure[i+1] - stop_seizure[i]\n",
        "    if distance_to_next_seizure < max_distance_filter:\n",
        "     \n",
        "    # Fill the 0 gaps in between with 1s\n",
        "     for j in range(stop_seizure[i], start_seizure[i+1], 1):\n",
        "       processed_predictions[j] = 1\n",
        "    \n",
        "    else: \n",
        "      continue\n",
        "\n",
        "\n",
        "  \n",
        "  # pruning most probably incorrect predictions - isolated, not long enough etc\n",
        "  # different function\n",
        "  # threshold controls how majny required to escape cutoff\n",
        "  final_prediction = eliminate_isolates(processed_predictions, threshold)\n",
        "  padding = 25\n",
        "  # final_prediction = pad_seizure_sites(final_prediction, padding)\n",
        "\n",
        "  return final_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kix2zxxkPvUo"
      },
      "outputs": [],
      "source": [
        "def pad_seizure_sites(sequence, pad):\n",
        "\n",
        "  seq_length = len(sequence)\n",
        "  seq_count, seq_start, seq_end = find_seizures(sequence, seq_length)\n",
        "\n",
        "  if len(seq_start)!=len(seq_end):\n",
        "    seq_end.append(seq_length)\n",
        "  \n",
        "  else:\n",
        "    pass\n",
        "\n",
        "  for i in range(0, len(seq_count)):\n",
        "\n",
        "    if seq_start[i] > pad:\n",
        "      for k in range(seq_start[i]-pad, seq_start[i]):\n",
        "        sequence[k] = 1\n",
        "\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    if seq_end[i] < seq_length - pad:    \n",
        "                                \n",
        "      for j in range(seq_end[i], seq_end[i]+pad):\n",
        "        sequence[j] = 1\n",
        "\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "\n",
        "  final_sequence = sequence\n",
        "\n",
        "  return final_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRxtOzYXGtfJ"
      },
      "outputs": [],
      "source": [
        "def find_seizures(binary_predictions, max_len):\n",
        "  # take in the list\n",
        "  # take max_seizure length - arbitrary - need to optimize \n",
        "  # \n",
        "  # initialize count and index start monitors\n",
        "  counts = []\n",
        "  index_at_seizure_start = []\n",
        "  index_at_seizure_end = []\n",
        "  length = 0\n",
        "\n",
        "  while length < max_len:\n",
        "    \n",
        "    # initialiez count, switch and iterator j\n",
        "    count = 1\n",
        "    switch = True\n",
        "    j = 1\n",
        "  \n",
        "    if binary_predictions[length] == 1:\n",
        "\n",
        "      # count consecutive ones: \n",
        "      while switch == True:\n",
        "        if length+j < max_len:\n",
        "\n",
        "          if binary_predictions[length+j] == 1:\n",
        "            count += 1\n",
        "            j += 1\n",
        "          elif binary_predictions[length+j] == 0:\n",
        "            ending_j = length + j - 1\n",
        "            index_at_seizure_end.append(ending_j)\n",
        "            break\n",
        "        \n",
        "        else:\n",
        "          break\n",
        "\n",
        "      \n",
        "      counts.append(count)\n",
        "      index_at_seizure_start.append(length)\n",
        "      # print(length)\n",
        "      # print(j)\n",
        "\n",
        "      length = length + j\n",
        "      # print(length)\n",
        "      # print(j)\n",
        "\n",
        "    else:\n",
        "      length +=1\n",
        "  \n",
        "\n",
        "  # If final seizure till the end:\n",
        "  if len(index_at_seizure_start) == len(index_at_seizure_end):\n",
        "    pass\n",
        "  \n",
        "  elif len(index_at_seizure_start) == len(index_at_seizure_end) + 1:\n",
        "    index_at_seizure_end.append(max_len)\n",
        "\n",
        "  else:\n",
        "    print(\"ANOTHER INDEXING ISSUE WITH FINDING SEIZURES\")\n",
        "  \n",
        "  return counts, index_at_seizure_start, index_at_seizure_end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO0leMs6-IIt"
      },
      "outputs": [],
      "source": [
        "def vectorized_stride(array, clearing_time_index, max_time, sub_window_size,\n",
        "                         stride_size):\n",
        "    start = clearing_time_index + 1 - sub_window_size + 1\n",
        "\n",
        "    sub_windows = (\n",
        "            start +\n",
        "            np.expand_dims(np.arange(sub_window_size), 0) +\n",
        "            # Create a rightmost vector as [0, V, 2V, ...].\n",
        "            np.expand_dims(np.arange(max_time + 1, step=stride_size), 0).T\n",
        "    )\n",
        "\n",
        "    return array[sub_windows]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3pSRFS6Tw0c"
      },
      "outputs": [],
      "source": [
        "def segmentor_test(subject):\n",
        "\n",
        "  # ros_test = RandomOverSampler(sampling_strategy=1.0, random_state=None)\n",
        "  # test array placeholder\n",
        "  testX = np.empty(shape=[0])\n",
        "  # test label array placeholder\n",
        "  testY = np.empty(shape=[0])\n",
        "\n",
        "  for i in range(0, len(subject)):\n",
        "    \n",
        "    print(\"Current subject:\", subject[i])\n",
        "    subj_array = np.load('/content/drive/MyDrive/Colab Notebooks/patient_arrays/{}'.format(subject[i]))\n",
        "    # Get data to single arrays\n",
        "    x_subj = subj_array[:, 0]\n",
        "    y_subj = subj_array[:, 1]\n",
        "    # x_subj = filter_sequence(x_subj, subject[i])\n",
        "\n",
        "    testX = np.concatenate((testX, x_subj), axis = 0)\n",
        "    testY = np.concatenate((testY, y_subj), axis = 0)\n",
        "\n",
        "  test_data_std = (testX - testX.mean()) / (testX.std())\n",
        "\n",
        "\n",
        "  # extract length of recording\n",
        "  length = np.size(test_data_std)\n",
        "  recording_length = int(length - 1)\n",
        "\n",
        "  # slice up training data\n",
        "  x_test_sliced = vectorized_stride(test_data_std, 1, max_time=recording_length, sub_window_size=1000,\n",
        "                                       stride_size=1000)\n",
        "  # slice up the label data\n",
        "  y_test_sliced = vectorized_stride(testY, 1, max_time=recording_length, sub_window_size=1000,\n",
        "                                       stride_size=1000)\n",
        "  \n",
        "  # touch up the label array (tuple to single value)\n",
        "  rows, columns = np.shape(y_test_sliced)\n",
        "\n",
        "  y_data = np.zeros(rows)\n",
        "  # iterate through rows:\n",
        "  for i in range(0, rows):\n",
        "      # iterate through row\n",
        "      if any(y_test_sliced[i]) == 1:\n",
        "        # print(\"Seizure\")\n",
        "        y_data[i] = 1\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "  return x_test_sliced, y_data.astype(int), y_test_sliced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVi6Vjn5-K1n"
      },
      "outputs": [],
      "source": [
        "def segmentor(sequence, name):\n",
        "    # Get data to single arrays\n",
        "  train_data_X = sequence[:, 0]\n",
        "  label_data = sequence[:, 1]\n",
        "\n",
        "  train_data_X = filter_sequence(train_data_X, name)\n",
        "\n",
        "  # Standardize the data\n",
        "  train_data_std = (train_data_X - train_data_X.mean()) / (train_data_X.std())\n",
        "  \n",
        "  if len(train_data_std) == len(label_data):\n",
        "    pass\n",
        "    # print(\"Lengths MATCH\")\n",
        "    \n",
        "  elif len(train_data_std) != len(label_data):\n",
        "    pass\n",
        "    # print(\"ERROR IN PREPROCESSING RECORDING\")\n",
        "\n",
        "\n",
        "    # extract length of recording\n",
        "  length = np.size(train_data_std)\n",
        "  recording_length = int(length - 1)\n",
        "\n",
        "    # slice up training data\n",
        "  x_train_sliced = vectorized_stride(train_data_std, 1, max_time=recording_length, sub_window_size=1000,\n",
        "                                      stride_size=250)\n",
        "    # slice up the label data\n",
        "  y_train_sliced = vectorized_stride(label_data, 1, max_time=recording_length, sub_window_size=1000,\n",
        "                                      stride_size=250)\n",
        "\n",
        "    # touch up the label array (tuple to single value)\n",
        "  rows, columns = np.shape(y_train_sliced)\n",
        "\n",
        "  y_data = np.zeros(rows)\n",
        "    # iterate through rows:\n",
        "  for i in range(0, rows):\n",
        "        # iterate through row\n",
        "    if any(y_train_sliced[i]) == 1:\n",
        "            # print(\"Seizure\")\n",
        "      y_data[i] = 1\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "\n",
        "  return x_train_sliced, y_data.astype(int), y_train_sliced"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_set_prep(subject_list):\n",
        "  ros_x = 0 # determine the upsampling ratio wrt. to majority\n",
        "  rus_x = 0 # determine donwsampling ratio wrt. to minority\n",
        "\n",
        "  ros = RandomOverSampler(sampling_strategy=ros_x, random_state=None)\n",
        "  rus = RandomUnderSampler(sampling_strategy=rus_x, random_state=None) \n",
        "  \n",
        "  # train array placeholder\n",
        "  X = np.empty(shape=[0, 1000])\n",
        "  # label array placeholder\n",
        "  Y = np.empty(shape=[0])\n",
        "\n",
        "  # iterate through subjects for training:\n",
        "  for i in range(0, len(subject_list)):\n",
        "\n",
        "      subj_array = np.load('/content/drive/MyDrive/Colab Notebooks/patient_arrays/{}'.format(subject_list[i]))\n",
        "      print(\"Current subject:\", subject_list[i])\n",
        "      x_subject, y_subject, _ = segmentor(subj_array, subject_list[i])\n",
        "\n",
        "      x_over, y_over = ros.fit_resample(x_subject, y_subject)\n",
        "      x_under, y_under = rus.fit_resample(x_over,y_over)\n",
        "      #x_under, y_under = ros.fit_resample(x_subject, y_subject)\n",
        "\n",
        "      X = np.concatenate((X, x_under), axis = 0)\n",
        "      Y = np.concatenate((Y, y_under), axis = 0)\n",
        "\n",
        "  # Check sample balance\n",
        "  print(\"label counts seizure:\", np.count_nonzero(Y == 1))      \n",
        "  print(\"label counts non-seizure:\", np.count_nonzero(Y == 0))      \n",
        "\n",
        "  rows_train, columns_train = np.shape(X)\n",
        "  X = X.reshape(rows_train, columns_train, 1)   \n",
        " \n",
        "  return X, Y\n"
      ],
      "metadata": {
        "id": "qq4GsaCGv7K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_subjects = ['train025_r2.npy','train163_r1.npy','train177_r4.npy','train178_r4.npy','train198_r2.npy','train203_r8.npy',\n",
        "'train226_r6.npy','train256_r12.npy','train256_r14.npy','train275_r29.npy','train275_r31.npy','train276_r5.npy','train276_r8.npy',\n",
        "'train276_r39.npy','train291_r15.npy','train291_r16.npy','train291_r21.npy','train291_r23.npy','train291_r25.npy','train291_r26.npy',\n",
        "'train307_r1.npy','train349_r3.npy','train353_r1.npy','train353_r6.npy','train357_r45.npy','train357_r58.npy']\n",
        "\n",
        "a = ['train025_r2.npy']\n",
        "b = ['train163_r1.npy']\n",
        "c = ['train177_r4.npy']\n",
        "d = ['train178_r4.npy']\n",
        "e = ['train198_r2.npy']\n",
        "f = ['train203_r8.npy']\n",
        "g = ['train226_r6.npy']\n",
        "h = ['train256_r12.npy','train256_r14.npy']\n",
        "i = ['train275_r29.npy','train275_r31.npy']\n",
        "j = ['train276_r5.npy','train276_r8.npy','train276_r39.npy']\n",
        "k = ['train291_r15.npy','train291_r16.npy','train291_r21.npy','train291_r23.npy','train291_r25.npy','train291_r26.npy']\n",
        "l = ['train307_r1.npy']\n",
        "m = ['train349_r3.npy']\n",
        "n = ['train353_r1.npy','train353_r6.npy']\n",
        "o = ['train357_r45.npy','train357_r58.npy']\n",
        "\n",
        "all_targets = [a,b,c,d,e,f,g,h,i,j,k,l,m,n,o]"
      ],
      "metadata": {
        "id": "w8YtPF-pmin8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(all_targets)):\n",
        "\n",
        "  all_subjects = ['train025_r2.npy','train163_r1.npy','train177_r4.npy','train178_r4.npy','train198_r2.npy','train203_r8.npy',\n",
        "  'train226_r6.npy','train256_r12.npy','train256_r14.npy','train275_r29.npy','train275_r31.npy','train276_r5.npy','train276_r8.npy',\n",
        "  'train276_r39.npy','train291_r15.npy','train291_r16.npy','train291_r21.npy','train291_r23.npy','train291_r25.npy','train291_r26.npy',\n",
        "  'train307_r1.npy','train349_r3.npy','train353_r1.npy','train353_r6.npy','train357_r45.npy','train357_r58.npy']\n",
        "\n",
        "\n",
        "  current_target = all_targets[i]\n",
        "  training_subjects = all_subjects\n",
        "  for j in range(0, len(current_target)):\n",
        "    training_subjects.remove(current_target[j])\n",
        "  \n",
        "  \n",
        "  print('training subjects: ', training_subjects)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBncPznwmin9",
        "outputId": "d3ebd9b1-676b-4fd7-bc7e-8aa926e4408d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training subjects:  ['train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train353_r1.npy', 'train353_r6.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train357_r45.npy', 'train357_r58.npy']\n",
            "training subjects:  ['train025_r2.npy', 'train163_r1.npy', 'train177_r4.npy', 'train178_r4.npy', 'train198_r2.npy', 'train203_r8.npy', 'train226_r6.npy', 'train256_r12.npy', 'train256_r14.npy', 'train275_r29.npy', 'train275_r31.npy', 'train276_r5.npy', 'train276_r8.npy', 'train276_r39.npy', 'train291_r15.npy', 'train291_r16.npy', 'train291_r21.npy', 'train291_r23.npy', 'train291_r25.npy', 'train291_r26.npy', 'train307_r1.npy', 'train349_r3.npy', 'train353_r1.npy', 'train353_r6.npy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kapdiJKf3eKE"
      },
      "source": [
        "Code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "824Ik5xvb1yA"
      },
      "source": [
        "Architecture assembly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fl = tfa.losses.SigmoidFocalCrossEntropy()"
      ],
      "metadata": {
        "id": "6D8k17K9wr5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def focal_loss_custom(alpha, gamma):\n",
        "   def binary_focal_loss(y_true, y_pred):\n",
        "      fl = tfa.losses.SigmoidFocalCrossEntropy(alpha=alpha, gamma=gamma)\n",
        "      y_true_K = K.ones_like(y_true)\n",
        "      focal_loss = fl(y_true, y_pred)\n",
        "      return focal_loss\n",
        "   return binary_focal_loss"
      ],
      "metadata": {
        "id": "T6wClckRwtxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Hybrid 1D CNN-LSTM Model\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=40, strides = 1, input_shape=(1000, 1)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling1D(pool_size=5, strides = 5))\n",
        "\n",
        "model.add(Conv1D(filters=32, kernel_size=20, strides = 1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling1D(pool_size=5, strides = 5))\n",
        "\n",
        "model.add(Conv1D(filters=64, kernel_size=5, strides = 1,  activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling1D(pool_size=5, strides = 1))\n",
        "\n",
        "model.add(LSTM(64, return_sequences = True))\n",
        "model.add(LSTM(64))\n",
        "\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer= regularizers.l2(0.001)))\n",
        "model.add(Dense(1, activation = 'sigmoid')) # sigmoid here adjust\n",
        "model.compile(optimizer='adam', loss=focal_loss_custom(alpha=0.2, gamma=2.0), metrics=\"binary_accuracy\")"
      ],
      "metadata": {
        "id": "rpyqEcyGlyUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Sku5ljUvTmVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_subjects = ['train025_r2.npy','train163_r1.npy','train177_r4.npy','train178_r4.npy','train198_r2.npy','train203_r8.npy',\n",
        "'train226_r6.npy','train256_r12.npy','train256_r14.npy','train275_r29.npy','train275_r31.npy','train276_r5.npy','train276_r8.npy',\n",
        "'train276_r39.npy','train291_r15.npy','train291_r16.npy','train291_r21.npy','train291_r23.npy','train291_r25.npy','train291_r26.npy',\n",
        "'train307_r1.npy','train349_r3.npy','train353_r1.npy','train353_r6.npy','train357_r45.npy','train357_r58.npy']\n",
        "\n",
        "a = ['train025_r2.npy'] # [X]\n",
        "b = ['train163_r1.npy']\n",
        "c = ['train177_r4.npy']\n",
        "d = ['train178_r4.npy']\n",
        "e = ['train198_r2.npy']\n",
        "f = ['train203_r8.npy']\n",
        "g = ['train226_r6.npy']\n",
        "h = ['train256_r12.npy','train256_r14.npy']\n",
        "i = ['train275_r29.npy','train275_r31.npy']\n",
        "j = ['train276_r5.npy','train276_r8.npy','train276_r39.npy']\n",
        "k = ['train291_r15.npy','train291_r16.npy','train291_r21.npy','train291_r23.npy','train291_r25.npy','train291_r26.npy']\n",
        "l = ['train307_r1.npy']\n",
        "m = ['train349_r3.npy']\n",
        "n = ['train353_r1.npy','train353_r6.npy']\n",
        "o = ['train357_r45.npy','train357_r58.npy']\n",
        "\n",
        "all_targets = [a,b,c,d,e,f,g,h,i,j,k,l,m,n,o]"
      ],
      "metadata": {
        "id": "_3ltdAMp0jnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(all_targets)):\n",
        "\n",
        "  all_subjects = ['train025_r2.npy','train163_r1.npy','train177_r4.npy','train178_r4.npy','train198_r2.npy','train203_r8.npy',\n",
        "  'train226_r6.npy','train256_r12.npy','train256_r14.npy','train275_r29.npy','train275_r31.npy','train276_r5.npy','train276_r8.npy',\n",
        "  'train276_r39.npy','train291_r15.npy','train291_r16.npy','train291_r21.npy','train291_r23.npy','train291_r25.npy','train291_r26.npy',\n",
        "  'train307_r1.npy','train349_r3.npy','train353_r1.npy','train353_r6.npy','train357_r45.npy','train357_r58.npy']\n",
        "\n",
        "\n",
        "  current_target = all_targets[i]\n",
        "  training_subjects = all_subjects\n",
        "  for j in range(0, len(current_target)):\n",
        "    training_subjects.remove(current_target[j])\n",
        "  \n",
        "  \n",
        "  print('training subjects: ', training_subjects)\n",
        "  "
      ],
      "metadata": {
        "id": "RLeu5Ozk0lGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leave-one-patient-out cross-validation scheme. In each iteration, a patient's recordings are removed and the rest used to train the model. "
      ],
      "metadata": {
        "id": "rjdMNrE8cvo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(all_targets)):\n",
        "\n",
        "  all_subjects = ['train025_r2.npy','train163_r1.npy','train177_r4.npy','train178_r4.npy','train198_r2.npy','train203_r8.npy',\n",
        "  'train226_r6.npy','train256_r12.npy','train256_r14.npy','train275_r29.npy','train275_r31.npy','train276_r5.npy','train276_r8.npy',\n",
        "  'train276_r39.npy','train291_r15.npy','train291_r16.npy','train291_r21.npy','train291_r23.npy','train291_r25.npy','train291_r26.npy',\n",
        "  'train307_r1.npy','train349_r3.npy','train353_r1.npy','train353_r6.npy','train357_r45.npy','train357_r58.npy']\n",
        "\n",
        "  current_target = all_targets[i]\n",
        "  training_subjects = all_subjects\n",
        "  for j in range(0, len(current_target)):\n",
        "    training_subjects.remove(current_target[j])\n",
        "  \n",
        "  print(\"Current target {}: {} \".format(i, current_target))\n",
        "  print(\"Training subjects {}: {}\".format(i, training_subjects))\n",
        "\n",
        "  test_X = 0\n",
        "  test_Y = 0\n",
        "  test_X, test_Y, _, = segmentor_test(current_target)\n",
        "  rows_test, columns_test = np.shape(test_X)\n",
        "  test_X = test_X.reshape(rows_test, columns_test, 1)\n",
        "  \n",
        "  train_X = 0\n",
        "  train_Y = 0\n",
        "  train_X, train_Y = train_set_prep(training_subjects)\n",
        "\n",
        "    # saving the history for model:\n",
        "\n",
        "    # Patient string truncation\n",
        "  n = 7\n",
        "  m = 5\n",
        "  model_name = current_target[0]\n",
        "  model_name = model_name[m:m+3]\n",
        "  # 227 repeat 3 SEEMS PROMISISNG!!!!\n",
        "  # 227 repeat 6_larger -- detected but high false rate. \n",
        "  model_name = 'patient'+model_name+'_227_REPEAT_9_larger'\n",
        "    \n",
        "  print(\"------------------------------------------------{}------------------------------------------------\".format(model_name))\n",
        "\n",
        "\n",
        "  patient_ID = current_target[0]\n",
        "  patient_ID = patient_ID[m:-n]\n",
        "    \n",
        "  patient_ID = 'Patient '+patient_ID\n",
        "  patient_ID = patient_ID[:-1]\n",
        "  log_path_name = model_name+'_training.log'\n",
        "  csv_logger = CSVLogger('/content/drive/MyDrive/Colab Notebooks/patient_MODELS_226/GPU_Traininglogs/{}'.format(log_path_name), separator=',', append=False)\n",
        "\n",
        "  optimal_checkpoint_model = model_name+'optimal_checkpoint'\n",
        "  es = EarlyStopping(monitor='val_binary_accuracy', mode='max', verbose=1, patience=50)\n",
        "  #es = EarlyStopping(monitor='val_binary_accuracy', mode='max', verbose=1, patience=30)\n",
        "  '''\n",
        "  mc = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/patient_MODELS_GPU_6_altImbalanceStrategy/GPU_Checkpoints_6/{}'.format(optimal_checkpoint_model),\n",
        "                      monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "  \n",
        "  '''    \n",
        "\n",
        "  mc = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/patient_MODELS_226/GPU_Checkpoints/{}'.format(optimal_checkpoint_model),\n",
        "                      monitor='val_binary_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "  \n",
        "  mc2 = ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/patient_MODELS_226/GPU_Checkpoints_loss/{}'.format(optimal_checkpoint_model),\n",
        "                      monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "  \n",
        "        \n",
        "\n",
        "\n",
        "  history = model.fit(train_X, train_Y, epochs = 50, batch_size = 2048, validation_data=(test_X, test_Y), callbacks=[csv_logger, es, mc, mc2], verbose = 1)\n",
        "  print(\"MODEL NAME: \", model_name)\n",
        "  model.save('/content/drive/MyDrive/Colab Notebooks/patient_MODELS_226/{}'.format(model_name))\n",
        "\n",
        "  test_y_pred = model.predict(test_X)\n",
        "  plt.plot(test_y_pred)\n",
        "  predictions = np.where(np.array(test_y_pred) >= 0.8,1, 0).tolist()\n",
        "  plt.plot(predictions)\n",
        "  flat_predictions =  [item for sublist in predictions for item in sublist]\n",
        "  flat_predictions = [ int(x) for x in flat_predictions ]\n",
        "  print(\"INITIAL FAR, SPEC,... \")\n",
        "  far, spec = calculate_FAR_Specificity(test_Y, flat_predictions)\n",
        "\n",
        "\n",
        "  print(\"Post_processed FAR, SPEC, ... \")\n",
        "  list_len = len(flat_predictions)\n",
        "  counts, start, end = find_seizures(flat_predictions, list_len)\n",
        "  count_real, start_real, end_real = find_seizures(test_Y, list_len)   \n",
        "  final_pred= predictions_post_processing(test_Y, flat_predictions, counts, start, end, 5, 2)\n",
        "  count_final, start_final, end_final = find_seizures(final_pred, list_len)\n",
        "  far, spec = calculate_FAR_Specificity(test_Y, final_pred)\n",
        "\n",
        "  print(\"------------------------------------------END CYCLE--------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "oAu5H4JOOjV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleans the seizure sites per observations in recordings - annotations done via EEG, do not exactly match the onset of the seizure int the EMG\n",
        "# FUNCTION NOT USED IN FINAL MODEL TRAINING\n",
        "def clean_seizure_sites(sequenceX, labelsY, patient_rec):\n",
        "\n",
        "  length_rec = len(sequenceX)\n",
        "  length_labels = len(labelsY)\n",
        "  print(length_rec)\n",
        "\n",
        "  if length_rec == length_labels:\n",
        "    pass\n",
        "    # print('MATCHING SEQ LENGTH CHECK GOOD')\n",
        "  else:\n",
        "    pass\n",
        "    # print('SEQUENC LEN NOT MATCHING')\n",
        "\n",
        "\n",
        "  if patient_rec == 'train025_r2.npy':\n",
        "    TRIM = 11000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "        \n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train163_r1.npy':\n",
        "    # patient 163_r1\n",
        "    # TRIM 7500\n",
        "    TRIM = 7500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] == 0 and labelsY[i] == 1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "    \n",
        "  elif patient_rec == 'train177_r4.npy':\n",
        "    # patient 177_r4\n",
        "    # TRIM 20000\n",
        "    TRIM = 20000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "  \n",
        "  elif patient_rec == 'train178_r4.npy':\n",
        "\n",
        "    # patient 178_r4 \n",
        "    # TRIM 8000\n",
        "    TRIM = 8000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "  \n",
        "  elif patient_rec == 'train198_r2.npy':\n",
        "    # patient 198_r2\n",
        "    # TRIM 7500\n",
        "    TRIM = 7500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train203_r8.npy':\n",
        "    # patient 203_r8\n",
        "    # TRIM 5000 from both 1 and 2\n",
        "    TRIM = 5000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train226_r6.npy':\n",
        "    # patient 226_r6\n",
        "    # TRIM 1000\n",
        "    TRIM = 1000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train256_r12.npy':\n",
        "    # patient 256_r12\n",
        "    # TRIM 7500\n",
        "    TRIM = 7500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "  elif patient_rec == 'train256_r14.npy':\n",
        "    # patient 256_r14\n",
        "    # TRIM 7500\n",
        "    TRIM = 7500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train275_r29.npy':\n",
        "    # patient 275_r29 --> INCLUDE\n",
        "    # TRIM = 5000\n",
        "    TRIM = 5000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train275_r31.npy':\n",
        "    # patient 275_r31 --> INCLUDE\n",
        "    # TRIM 12500\n",
        "    TRIM = 12500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train276_r5.npy':\n",
        "    # patietn 276_r5\n",
        "    # TRIM 25000\n",
        "    TRIM = 25000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train276_r8.npy':\n",
        "    # patient 276_r8\n",
        "    # TRIM 10000\n",
        "    TRIM = 10000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "  elif patient_rec == 'train276_r39.npy':\n",
        "\n",
        "    # patient 276_r39\n",
        "    # TRIM 3000\n",
        "    TRIM = 3000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "  elif patient_rec == 'train291_r15.npy':\n",
        "    # patient 291_r15\n",
        "    # TRIM 14000\n",
        "    TRIM = 14000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "  \n",
        "  elif patient_rec == 'train291_r16.npy':\n",
        "    # patient 291_r16\n",
        "    # TRIM 12000\n",
        "    TRIM = 12000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "  elif patient_rec == 'train291_r21.npy':\n",
        "    # patient 291_r21\n",
        "    # TRIM 12500\n",
        "    TRIM = 12500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train291_r23.npy':\n",
        "\n",
        "    # patient 291_r23\n",
        "    # TRIM 12500\n",
        "    TRIM = 12500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train291_r25.npy':\n",
        "     # patient 291_r25\n",
        "    # TRIM 12500\n",
        "    TRIM = 12500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "  elif patient_rec == 'train291_r26.npy':\n",
        "    # patient 291_r26\n",
        "    # TRIM 12500\n",
        "    TRIM = 12500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train307_r1.npy':\n",
        "    # patient 307_r1\n",
        "    # TRIM 6000 first\n",
        "    # TRIM 2500 second\n",
        "    TRIM = 6000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "  elif patient_rec == 'train349_r3.npy':\n",
        "    # patient 349_r3\n",
        "    # TRIM 7500\n",
        "    TRIM = 7500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train353_r1.npy':\n",
        "    # patient 353_r1\n",
        "    # TRIM 12500\n",
        "    TRIM = 12500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train353_r6.npy':\n",
        "\n",
        "    # patient 353_r6\n",
        "    # TRIM 6000\n",
        "    TRIM = 6000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "  elif patient_rec == 'train357_r45.npy':\n",
        "    # patient 357_r45\n",
        "    # TRIM 2500\n",
        "    TRIM = 2500\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "\n",
        "  elif patient_rec == 'train357_r58.npy':\n",
        "\n",
        "    # patient 357_r58\n",
        "    # TRIM 5000\n",
        "    TRIM = 5000\n",
        "    for i in range(0, length_labels):\n",
        "      if labelsY[i] == 0:\n",
        "        pass\n",
        "      elif labelsY[i-1] ==0 and labelsY[i] ==1:\n",
        "        print('Removing the first {} sample points from the seizure site'.format(TRIM))\n",
        "        start_delete_row = i\n",
        "        end_delete_row = i+TRIM\n",
        "        deletion_range = np.arange(start_delete_row, end_delete_row, 1)\n",
        "        labelsY = np.delete(labelsY, deletion_range, axis = 0)\n",
        "        sequenceX = np.delete(sequenceX, deletion_range, axis = 0)\n",
        "\n",
        "        break\n",
        "  \n",
        "  return sequenceX, labelsY"
      ],
      "metadata": {
        "id": "hNLfxro9cdC9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}